# Dependency Parser (Arc-Eager)

This repository contains an implementation of a **Transition-Based Dependency Parser** using the **Arc-Eager** system. It handles **Non-Projective** dependencies via a pseudo-projective transformation pipeline (Extra Credit). This as part of the Assignment guidelines for the second Assignment in the course Linguistic Data Analysis 3: Data Modelling in ILs.

The parser is designed to work with the **Hindi Dependency Treebank (HDTB)** in CoNLL format.

## üìÇ File Structure

* **`transition.py`**: Implements the core Arc-Eager transition system.
    * Defines the 4 transitions: `SHIFT`, `REDUCE`, `LEFT-ARC`, `RIGHT-ARC`.
    * Manages the configuration state (Stack, Buffer, Arcs).
* **`oracle.py`**: The main entry point for the parser.
    * Implements the **Static Oracle** (Goldberg & Nivre, 2012) to predict the next move based on the Gold tree.
    * Contains the training/parsing loop with a "safety valve" to prevent infinite loops on malformed data.
    * Includes robust data preprocessing to handle raw HDTB CoNLL files (filtering metadata/XML).
* **`projectivize.py`** (Extra Credit): A module to handle non-projective trees.
    * **Encode:** Lifts non-projective arcs to their grandparents until the tree is projective (pseudo-projective transformation).
    * **Decode:** Restores the lifted arcs to their original heads after parsing.
* **`hindi.tab`**: The input Development Set from the Hindi Treebank (News Domain, Romanized/wx format).
* **`hindi_proj.tab`**: Intermediate file generated by `projectivize.py encode`. Contains the projectivized version of the input data (no crossing arcs).
* **`hindi_proj.out`**: Intermediate file generated by `oracle.py`. Contains the parser's output on the projectivized data.
* **`final.out`**: The final output of the parser after the full projectivization pipeline (Decode step).

## üöÄ How to Run

### Prerequisites
* Python 3.x

### 1. Standard Parsing (Projective Only)
To run the parser directly on the input file without handling non-projectivity:

```bash
python3 oracle.py tab < hindi.tab > hindi_baseline.out
```

### 2. Extra Credit Pipeline (Handling Non-Projectivity)
To correctly parse non-projective Hindi sentences, run the following 3-step pipeline:

- Step 1: Encode (Projectivize the Training Data)
Lifts crossing arcs to create a strictly projective version of the treebank.

```bash
python3 projectivize.py encode < hindi.tab > hindi_proj.tab
```

- Step 2: Parse (Train/Test on Projective Data)
Runs the Arc-Eager oracle on the simplified, projective data.

```bash
python3 oracle.py tab < hindi_proj.tab > hindi_proj.out
```

- Step 3: Decode (Deprojectivize the Output)
Restores the original non-projective arcs based on the encoded labels (e.g., LABEL^HEAD).

```bash
python3 projectivize.py decode < hindi_proj.out > final.out
```

## üìù Implementation Details
### Transition System
The parser uses the standard Arc-Eager system:

- Left-Arc: Creates a dependency head $\leftarrow$ dependent if the head is in the buffer.
- Right-Arc: Creates a dependency dependent $\rightarrow$ head if the head is in the stack.
- Shift: Pushes words onto the stack.
- Reduce: Pops the stack if the word has a head.

### Robustness Features
- Data Cleaning: The read_sentences function automatically filters out XML tags (e.g., <Sentence id=...>) and malformed lines often found in the raw HDTB distribution.
- Infinite Loop Protection: A safety mechanism forces a generic SHIFT or REDUCE if the oracle gets stuck in a state where no valid move exists (common in noisy real-world data).

## Citations
- Algorithm: Nivre (2003), Goldberg & Nivre (2012).
- Dataset: Hindi Dependency Treebank (HDTB) v0.5.